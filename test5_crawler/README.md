# 教程
## test1
    https://www.bilibili.com/video/BV1d54y1g7db/
## test2
    https://www.bilibili.com/video/BV1Db4y1m7Ho?p=51
    百度网盘下载：https://pan.baidu.com/s/15RVioBZssHv7ePhlHrchtQ ，提取码：yyds 
    bs4教程：https://beautifulsoup.cn/、https://beautiful-soup-4.readthedocs.io/en/latest/
    requests教程：https://requests.readthedocs.io/projects/cn/zh-cn/latest/
    scrapy：https://scrapy-16.readthedocs.io/zh-cn/1.6/、https://www.runoob.com/w3cnote/scrapy-detail.html

# 安装
1. requests ```pip install requests```
2. bs4 ```pip install bs4```
3. xpath ```https://chromewebstore.google.com/detail/xpath-helper/hgimnogjllphhhkhlmebbmlgjoejdpjl?hl=zh-CN&utm_source=ext_sidebar```
4. xmlx ```pip install lxml ‐i https://pypi.douban.com/simple```
5. scrapy ```pip install scrapy```  ，```pip install ipython```
   注意：如果是使用Anaconda按照的scrapy，则必须进入Anaconda对应的环境才有scrapy命令

# 使用步骤
1. 指定url
2. 发起请求
3. 获取响应数据
4. 解析数据
5. 数据分析
6. 持久化数据

# 检查某个网站的哪些页面允许被爬虫
    domain/robots.txt